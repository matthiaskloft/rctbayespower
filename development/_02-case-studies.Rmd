---
title: "Case Studies: Real-World Applications of Bayesian Power Analysis"
date: "`r Sys.Date()`"
always_allow_html: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "/man/figures/01-introduction-",
  out.width = "90%",
  fig.width = 10,
  fig.height = 7,
  message = FALSE
)

# Set CRAN mirror
options(repos = c(CRAN = "https://cloud.r-project.org/"))

# Check and install required packages
packages <- c("tidyverse", "devtools")
install.packages(setdiff(packages, rownames(installed.packages())))
invisible(lapply(packages, require, character.only = TRUE))

# Load the package
devtools::load_all(".")

# Fast performance testing settings
n_cores <- parallel::detectCores() - 1
n_sims <- n_cores * 10
```

# Real-World Case Studies

This vignette presents real-world case studies demonstrating how to apply Bayesian power analysis using the `rctbayespower` package across different clinical domains, with actual model fitting.


# Case Study 1: Cardiovascular Clinical Trial

## Background

A pharmaceutical company wants to test a new medication for reducing LDL cholesterol. Based on previous studies:

- Current standard treatment reduces LDL by 30 mg/dL on average
- New treatment is expected to reduce LDL by an additional 15 mg/dL
- Standard deviation of LDL change is approximately 40 mg/dL
- Clinically meaningful difference is 10 mg/dL

## Study Design

```{r cardio_setup}
# Convert to standardized effect size
baseline_sd <- 40
additional_reduction <- 15
effect_size <- additional_reduction / baseline_sd # Cohen's d = 0.375

# Clinically meaningful difference
clinical_threshold <- 10 / baseline_sd # 0.25

cat("Expected effect size (Cohen's d):", round(effect_size, 3), "\n")
cat("Clinical threshold:", round(clinical_threshold, 3), "\n")
```

## Power Analysis

```{r cardio_power}
# Initial power analysis
cardio_power <- power_analysis_ancova(
  n_control = 100,
  n_treatment = 100,
  effect_size = 0.375,
  baseline_effect = 0.5, # Strong baseline effect (LDL at screening)
  outcome_type = "continuous",
  threshold_success = 0.25, # Based on clinical threshold
  threshold_futility = 0.1,
  p_sig_success = 0.95,
  p_sig_futility = 0.5,
  n_simulations = n_sims,
  n_cores = n_cores,
  brms_args = list(
    chains = 4,
    iter = 800,
    warmup = 300
  )
)

print(cardio_power)
```

## Sample Size Determination

```{r cardio_sample_size}
# Find optimal sample size for regulatory submission
cardio_sample_size <- power_grid_analysis(
  sample_sizes = c(80, 120, 160, 200),
  effect_sizes = 0.375, # Fixed effect size
  target_power_success = 0.85, # Higher power for regulatory submission
  target_power_futility = 0.8,
  power_analysis_fn = "power_analysis_ancova",
  outcome_type = "continuous",
  baseline_effect = 0.5,
  threshold_success = 0.25,
  threshold_futility = 0.1,
  p_sig_success = 0.95,
  p_sig_futility = 0.5,
  n_simulations = n_sims,
  n_cores = n_cores,
  brms_args = list(
    chains = 4,
    iter = 800,
    warmup = 300
  )
)

print(cardio_sample_size)
```

```{r cardio_plot}
# Plot sample size curve
plot(cardio_sample_size, type = "power_curve")
```

## Incorporating Prior Information

```{r cardio_prior}
# Meta-analysis of similar drugs with design prior
cardio_informed <- power_grid_analysis(
  sample_sizes = 120,
  effect_sizes = seq(0.2, 0.6, by = 0.05),
  design_prior = "normal(0.375, 0.1)", # Informed by meta-analysis
  power_analysis_fn = "power_analysis_ancova",
  outcome_type = "continuous",
  baseline_effect = 0.5,
  threshold_success = 0.25,
  threshold_futility = 0.1,
  p_sig_success = 0.95,
  p_sig_futility = 0.5,
  n_simulations = n_sims,
  n_cores = n_cores,
  brms_args = list(
    chains = 4,
    iter = 800,
    warmup = 300
  )
)

cat("Integrated power with informed prior:", round(cardio_informed$integrated_power_success, 3), "\n")
```

```{r cardio_prior_plot}
plot(cardio_informed, type = "power_curve", show_integrated = TRUE)
```

# Case Study 2: Mental Health Intervention

## Background

A clinical psychologist wants to test a new cognitive behavioral therapy (CBT) protocol for depression. The study will use:

- Primary outcome: Change in Beck Depression Inventory (BDI-II) score
- Expected treatment effect: 5-point reduction (scale 0-63)
- Standard deviation: 12 points
- Clinically meaningful difference: 3 points
- Include baseline severity and age as covariates

## Study Design

```{r mental_health_setup}
# Effect size calculation
baseline_sd <- 12
expected_reduction <- 5
effect_size <- expected_reduction / baseline_sd # Cohen's d ≈ 0.42

# Clinical threshold
clinical_threshold <- 3 / baseline_sd # 0.25

cat("Expected effect size:", round(effect_size, 3), "\n")
cat("Clinical threshold:", round(clinical_threshold, 3), "\n")
```

## Power Analysis with Strong Baseline Effects

Mental health studies typically have strong baseline covariate effects:

```{r mental_health_power}
# Power analysis with strong baseline effect
depression_power <- power_analysis_ancova(
  n_control = 60,
  n_treatment = 60,
  effect_size = 0.42,
  baseline_effect = 0.7, # Strong baseline severity effect
  outcome_type = "continuous",
  threshold_success = 0.25, # Clinically meaningful threshold
  threshold_futility = 0.1,
  p_sig_success = 0.95,
  p_sig_futility = 0.5,
  n_simulations = n_sims,
  n_cores = n_cores,
  brms_args = list(
    chains = 4,
    iter = 800,
    warmup = 300
  )
)

# Compare with analysis without strong baseline effect
depression_power_weak <- power_analysis_ancova(
  n_control = 60,
  n_treatment = 60,
  effect_size = 0.42,
  baseline_effect = 0.2, # Weak baseline effect
  outcome_type = "continuous",
  threshold_success = 0.25,
  threshold_futility = 0.1,
  p_sig_success = 0.95,
  p_sig_futility = 0.5,
  n_simulations = n_sims,
  n_cores = n_cores,
  brms_args = list(
    chains = 4,
    iter = 800,
    warmup = 300
  )
)

cat("Power with strong baseline effect:", round(depression_power$power_success, 3), "\n")
cat("Power with weak baseline effect:", round(depression_power_weak$power_success, 3), "\n")
```

## Sensitivity to Effect Size

```{r mental_health_sensitivity}
# Test sensitivity to different effect sizes
depression_curve <- power_grid_analysis(
  sample_sizes = 60,
  effect_sizes = seq(0.2, 0.7, by = 0.1),
  design_prior = "normal(0.42, 0.1)", # Prior based on pilot study
  power_analysis_fn = "power_analysis_ancova",
  outcome_type = "continuous",
  baseline_effect = 0.7,
  threshold_success = 0.25,
  threshold_futility = 0.1,
  p_sig_success = 0.95,
  p_sig_futility = 0.5,
  n_simulations = n_sims,
  n_cores = n_cores,
  brms_args = list(
    chains = 4,
    iter = 800,
    warmup = 300
  )
)

print(depression_curve)
```

```{r mental_health_plot}
plot(depression_curve, type = "power_curve", show_integrated = TRUE)
```

# Case Study 3: Rare Disease Trial

## Background

A biotechnology company is developing a treatment for a rare genetic disorder affecting approximately 1 in 50,000 people. Challenges include:

- Very small potential sample size (n ≈ 30 total)
- High variability in outcomes
- Strong biological rationale for treatment
- Binary outcome: treatment response (yes/no)
- Historical response rate: 15%
- Expected response rate with treatment: 40%

## Design Considerations

```{r rare_disease_setup}
# Convert to log odds ratio
baseline_prob <- 0.15
treatment_prob <- 0.40

baseline_odds <- baseline_prob / (1 - baseline_prob)
treatment_odds <- treatment_prob / (1 - treatment_prob)
log_odds_ratio <- log(treatment_odds / baseline_odds)

cat("Baseline response rate:", baseline_prob, "\n")
cat("Expected treatment response rate:", treatment_prob, "\n")
cat("Log odds ratio:", round(log_odds_ratio, 3), "\n")
```

## Power Analysis for Small Sample

```{r rare_disease_power}
# Power analysis with very small sample
rare_disease_power <- power_analysis_ancova(
  n_control = 15,
  n_treatment = 15,
  effect_size = log_odds_ratio, # Log odds ratio
  baseline_effect = 0.2, # Some baseline predictors
  outcome_type = "binary",
  baseline_prob = 0.15,
  threshold_success = 0.8, # Lower threshold given small sample
  threshold_futility = 0.2,
  p_sig_success = 0.9, # Lower probability threshold
  p_sig_futility = 0.9,
  n_simulations = n_sims,
  n_cores = n_cores,
  brms_args = list(
    chains = 4,
    iter = 800,
    warmup = 300
  )
)

print(rare_disease_power)
```

## Effect of Different Sample Sizes

```{r rare_disease_alternatives}
# Explore different allocation strategies
rare_disease_sample_sizes <- power_grid_analysis(
  sample_sizes = c(15, 20, 25, 30),
  effect_sizes = log_odds_ratio,
  power_analysis_fn = "power_analysis_ancova",
  outcome_type = "binary",
  baseline_prob = 0.15,
  baseline_effect = 0.2,
  threshold_success = 0.8,
  threshold_futility = 0.2,
  p_sig_success = 0.9,
  p_sig_futility = 0.9,
  n_simulations = n_sims,
  n_cores = n_cores,
  brms_args = list(
    chains = 4,
    iter = 800,
    warmup = 300
  ))
)

print(rare_disease_sample_sizes)
```

```{r rare_disease_plot}
plot(rare_disease_sample_sizes, type = "power_curve")
```

# Case Study 4: Public Health Intervention

## Background

A public health intervention to reduce hospital readmissions is being tested:

- Primary outcome: 30-day readmission rate (binary)
- Expected baseline rate: 12%
- Expected reduction: 3 percentage points (to 9%)
- Large sample available (hospital-level implementation)
- Strong administrative predictors available

## Design Effect Calculation

```{r public_health_setup}
# Calculate effect size
baseline_rate <- 0.12
treatment_rate <- 0.09 # 3 percentage point reduction

# Convert to log odds ratio
baseline_odds <- baseline_rate / (1 - baseline_rate)
treatment_odds <- treatment_rate / (1 - treatment_rate)
public_health_log_or <- log(treatment_odds / baseline_odds)

cat("Baseline readmission rate:", baseline_rate, "\n")
cat("Expected treatment rate:", treatment_rate, "\n")
cat("Log odds ratio:", round(public_health_log_or, 3), "\n")
```

## Power Analysis

```{r public_health_power}
# Power analysis for public health intervention
public_health_power <- power_analysis_ancova(
  n_control = 1000, # Large sample from administrative data
  n_treatment = 1000,
  effect_size = public_health_log_or,
  baseline_effect = 0.4, # Strong administrative predictors
  outcome_type = "binary",
  baseline_prob = baseline_rate,
  threshold_success = abs(public_health_log_or) * 0.5, # 50% of expected effect
  threshold_futility = 0.05,
  p_sig_success = 0.95,
  p_sig_futility = 0.5,
  n_simulations = n_sims,
  n_cores = n_cores,
  brms_args = list(
    chains = 4,
    iter = 800,
    warmup = 300
  )
)

print(public_health_power)
```

## Cost-Effectiveness Analysis

```{r public_health_cost}
# Analyze cost-effectiveness for different sample sizes
public_health_cost_analysis <- function(sample_sizes, cost_per_participant = 50, fixed_costs = 100000) {
  cost_results <- data.frame(
    Sample_Size = numeric(),
    Total_Cost = numeric(),
    Power_Success = numeric(),
    Cost_Per_Power_Unit = numeric(),
    stringsAsFactors = FALSE
  )

  for (n in sample_sizes) {
    power_result <- power_analysis_ancova(
      n_control = n,
      n_treatment = n,
      effect_size = public_health_log_or,
      baseline_effect = 0.4,
      outcome_type = "binary",
      baseline_prob = baseline_rate,
      threshold_success = abs(public_health_log_or) * 0.5,
      threshold_futility = 0.05,
      n_simulations = n_sims,
      n_cores = n_cores,
      brms_args = list(
    chains = 4,
    iter = 800,
    warmup = 300
  )
    )

    total_cost <- fixed_costs + (2 * n * cost_per_participant)
    cost_per_power <- total_cost / power_result$power_success

    cost_results <- rbind(cost_results, data.frame(
      Sample_Size = n,
      Total_Cost = total_cost,
      Power_Success = power_result$power_success,
      Cost_Per_Power_Unit = cost_per_power
    ))
  }

  return(cost_results)
}

# Analyze cost-effectiveness
ph_cost_analysis <- public_health_cost_analysis(
  sample_sizes = c(500, 750, 1000, 1250),
  cost_per_participant = 50,
  fixed_costs = 100000
)

print(ph_cost_analysis)

# Find most cost-effective design
optimal_ph_design <- ph_cost_analysis[which.min(ph_cost_analysis$Cost_Per_Power_Unit), ]
cat("Most cost-effective design:\n")
cat("Sample size per group:", optimal_ph_design$Sample_Size, "\n")
cat("Total cost: $", format(optimal_ph_design$Total_Cost, big.mark = ","), "\n")
cat("Power:", round(optimal_ph_design$Power_Success, 3), "\n")
```



***


# Session Information

```{r session_info}
sessionInfo()
```
