---
title: "Algorithm Performance and Computational Considerations"
author: "rctbayespower package authors"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{Algorithm Performance and Computational Considerations}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  warning = FALSE,
  message = FALSE
)

# Fast performance testing settings
n_sims_perf <- 3 # Minimal simulations for performance testing
n_cores_perf <- 1 # Single core for consistent timing
```

# Algorithm Performance and Computational Considerations

This vignette provides guidance on algorithm selection, performance optimization, and computational considerations when using the `rctbayespower` package for Bayesian power analysis.

```{r load_libs, echo=FALSE}
library(rctbayespower)
library(ggplot2)
library(dplyr)
```

# Algorithm Overview

The `rctbayespower` package supports multiple algorithms with different speed-accuracy trade-offs:

## Algorithm Types

```{r algorithm_overview}
# Algorithm comparison table
algorithm_comparison <- data.frame(
  Algorithm = c("meanfield", "fullrank", "sampling"),
  Speed = c("Fastest", "Medium", "Slowest"),
  Accuracy = c("Good", "Better", "Best"),
  Use_Case = c("Exploration", "Refinement", "Final confirmation"),
  Typical_Time = c("Seconds", "Minutes", "Hours"),
  stringsAsFactors = FALSE
)

print(algorithm_comparison)
```

## Selection Strategy

**Recommended workflow:**
1. **Exploration**: `meanfield` for rapid screening
2. **Refinement**: `fullrank` for detailed analysis
3. **Confirmation**: `sampling` for final results

# Performance Comparison

## Basic Algorithm Comparison

```{r basic_performance}
# Compare core algorithms on standard problem
performance_results <- data.frame(
  Algorithm = character(),
  Time_Seconds = numeric(),
  Power_Success = numeric(),
  Convergence = numeric(),
  stringsAsFactors = FALSE
)

algorithms <- c("meanfield", "fullrank")

for (alg in algorithms) {
  cat("Testing algorithm:", alg, "\n")
  
  start_time <- Sys.time()
  
  power_result <- power_analysis_ancova(
    n_control = 60,
    n_treatment = 60,
    effect_size = 0.5,
    baseline_effect = 0.3,
    outcome_type = "continuous",
    threshold_success = 0.3,
    threshold_futility = 0.1,
    n_simulations = n_sims_perf,
    n_cores = n_cores_perf,
    brms_args = list(
      algorithm = alg,
      importance_resampling = TRUE,
      iter = 1e4,
      output_samples = 1e3
    )
  )
  
  elapsed_time <- as.numeric(difftime(Sys.time(), start_time, units = "secs"))
  
  performance_results <- rbind(performance_results, data.frame(
    Algorithm = alg,
    Time_Seconds = elapsed_time,
    Power_Success = power_result$power_success,
    Convergence = power_result$convergence
  ))
}

print(performance_results)

# Calculate efficiency (accuracy per unit time)
performance_results$Efficiency <- performance_results$Power_Success / performance_results$Time_Seconds
cat("\nEfficiency (power per second):\n")
print(performance_results[c("Algorithm", "Efficiency")])
```

## Grid Analysis Performance

```{r grid_performance}
# Demonstrate model caching benefits
cat("Grid analysis with model caching:\n")
system.time({
  grid_result <- power_grid_analysis(
    sample_sizes = c(60, 80, 100),
    effect_sizes = c(0.4, 0.5, 0.6),
    power_analysis_fn = "power_analysis_ancova",
    outcome_type = "continuous",
    baseline_effect = 0.3,
    threshold_success = 0.3,
    threshold_futility = 0.1,
    n_simulations = n_sims_perf,
    n_cores = n_cores_perf,
    brms_args = list(
      algorithm = "meanfield",
      importance_resampling = TRUE,
      iter = 1e4,
      output_samples = 1e3
    )
  )
})

cat("Grid completed:", nrow(grid_result), "combinations\n")
cat("Average power:", round(mean(grid_result$power_success), 3), "\n")
```

# Computational Requirements

## Memory Guidelines

```{r memory_guidelines}
memory_guide <- data.frame(
  Component = c("Base session", "Small analysis", "Medium grid", "Large grid"),
  Memory_MB = c("~50", "~100", "~300", "~1000+"),
  Notes = c("R + packages", "Single power analysis", "5x5 grid", "10x10+ grid"),
  stringsAsFactors = FALSE
)

print(memory_guide)
```

## Time Estimates

```{r time_estimates}
time_guide <- data.frame(
  Analysis_Type = c("Single analysis", "Small grid (3x3)", "Medium grid (5x5)", "Large grid (10x10)"),
  Meanfield = c("30-60 sec", "5-10 min", "15-30 min", "2-4 hours"),
  Fullrank = c("1-2 min", "10-20 min", "30-60 min", "4-8 hours"),
  Notes = c("100 simulations", "900 total fits", "2500 total fits", "10000 total fits"),
  stringsAsFactors = FALSE
)

print(time_guide)
```

# Optimization Strategies

## Progressive Workflow

```{r optimization_demo}
# Demonstrate efficient 3-stage workflow
cat("=== Optimized Workflow Example ===\n")

# Stage 1: Fast exploration
cat("Stage 1: Exploration with meanfield\n")
start_time <- Sys.time()

exploration <- power_grid_analysis(
  sample_sizes = c(60, 80, 100),
  effect_sizes = c(0.3, 0.5, 0.7),
  power_analysis_fn = "power_analysis_ancova",
  outcome_type = "continuous",
  baseline_effect = 0.3,
  threshold_success = 0.3,
  threshold_futility = 0.1,
  n_simulations = 2, # Very fast
  n_cores = n_cores_perf,
  brms_args = list(algorithm = "meanfield", importance_resampling = TRUE, iter = 1e4, output_samples = 1e3)
)

stage1_time <- difftime(Sys.time(), start_time, units = "secs")
cat("  Completed in", round(stage1_time, 1), "seconds\n")

# Stage 2: Focused analysis
cat("Stage 2: Refinement with fullrank\n")
start_time <- Sys.time()

# Focus on promising region
focused <- power_analysis_ancova(
  n_control = 80,  # Best from stage 1
  n_treatment = 80,
  effect_size = 0.5,
  baseline_effect = 0.3,
  outcome_type = "continuous",
  threshold_success = 0.3,
  threshold_futility = 0.1,
  n_simulations = n_sims_perf,
  n_cores = n_cores_perf,
  brms_args = list(algorithm = "fullrank", importance_resampling = TRUE, iter = 1e4, output_samples = 1e3)
)

stage2_time <- difftime(Sys.time(), start_time, units = "secs")
cat("  Completed in", round(stage2_time, 1), "seconds\n")

total_time <- stage1_time + stage2_time
cat("Total workflow time:", round(total_time, 1), "seconds\n")
cat("Final power estimate:", round(focused$power_success, 3), "\n")
```

# Platform Considerations

## Hardware Recommendations

```{r hardware_recs}
hardware_guide <- data.frame(
  Use_Case = c("Learning", "Research", "Production"),
  RAM_GB = c("8+", "16+", "32+"),
  CPU_Cores = c("4+", "8+", "16+"),
  Storage = c("SSD", "Fast SSD", "NVMe SSD"),
  stringsAsFactors = FALSE
)

print(hardware_guide)
```

## Parallel Processing

```{r parallel_guide}
parallel_guide <- data.frame(
  Cores = c("1", "2-4", "8+"),
  Strategy = c("Sequential", "Parallel simulations", "Full parallelization"),
  Memory_Per_Core = c("2-4 GB", "1-2 GB", "1-2 GB"),
  Best_For = c("Small analyses", "Medium grids", "Large grids"),
  stringsAsFactors = FALSE
)

print(parallel_guide)
```

# Troubleshooting

## Common Issues

```{r troubleshooting}
issues_guide <- data.frame(
  Problem = c("Slow fitting", "Memory errors", "Low convergence"),
  Solution = c("Use faster algorithm", "Reduce sample size", "Increase iterations"),
  Prevention = c("Start with meanfield", "Monitor memory", "Validate models first"),
  stringsAsFactors = FALSE
)

print(issues_guide)
```

## Performance Monitoring

```{r monitoring_example, eval=FALSE}
# Example performance monitoring code
monitor_performance <- function(analysis_function) {
  # Monitor memory
  initial_memory <- object.size(ls())
  
  # Time the analysis
  start_time <- Sys.time()
  result <- analysis_function()
  elapsed <- difftime(Sys.time(), start_time, units = "secs")
  
  # Check convergence
  if (result$convergence < 0.95) {
    warning("Low convergence: ", result$convergence)
  }
  
  cat("Analysis completed in", round(elapsed, 1), "seconds\n")
  cat("Convergence rate:", round(result$convergence, 3), "\n")
  
  return(result)
}
```

# Best Practices

## Quick Reference

1. **Algorithm Selection**:
   - Exploration: `meanfield`
   - Refinement: `fullrank` 
   - Final analysis: `sampling` or high-precision variational

2. **Performance Optimization**:
   - Use model caching for grids
   - Start broad, then focus
   - Monitor convergence rates
   - Plan computational resources

3. **Quality Assurance**:
   - Check convergence (â‰¥95%)
   - Cross-validate with different algorithms
   - Document computational choices

## Resource Planning

```{r resource_planning}
# Quick calculator for analysis complexity
calculate_complexity <- function(n_sample_sizes, n_effect_sizes, n_simulations) {
  total_fits <- n_sample_sizes * n_effect_sizes * n_simulations
  
  # Rough time estimates (minutes)
  time_meanfield <- total_fits / 100  # ~100 fits per minute
  time_fullrank <- total_fits / 50    # ~50 fits per minute
  
  cat("Analysis complexity:\n")
  cat("  Total model fits:", total_fits, "\n")
  cat("  Estimated time (meanfield):", round(time_meanfield, 1), "minutes\n")
  cat("  Estimated time (fullrank):", round(time_fullrank, 1), "minutes\n")
}

# Example: medium grid analysis
calculate_complexity(n_sample_sizes = 5, n_effect_sizes = 5, n_simulations = 100)
```

# Conclusion

Effective use of `rctbayespower` requires balancing computational efficiency with analytical precision:

- **Start fast**: Use `meanfield` for exploration
- **Refine carefully**: Use `fullrank` for detailed analysis  
- **Confirm precisely**: Use `sampling` for final results
- **Plan resources**: Estimate time and memory needs
- **Monitor quality**: Check convergence and validate results

The progressive workflow approach maximizes efficiency while maintaining result quality.

# Session Information

```{r session_info}
sessionInfo()
```