---
title: "Getting Started with 'rctbayespower'"
author:
 - name: Matthias Kloft
   orcid: 0000-0003-1845-6957
date: "`r Sys.Date()`"
always_allow_html: true
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "../man/figures/README-",
  out.width = "90%",
  fig.width = 10,
  fig.height = 7,
  message = FALSE
)

# Set CRAN mirror
options(repos = c(CRAN = "https://cloud.r-project.org/"))

# Check and install required packages
packages <- c("dplyr", "kableExtra")
install.packages(setdiff(packages, rownames(installed.packages())))
invisible(lapply(packages, require, character.only = TRUE))

# Load rctbayespower package
library(rctbayespower)
```

Setup:
```{r}
# Set number of cores and simulations:
n_cores <- min(4, parallel::detectCores())
# low number of simulations for vignette
n_sims <- 200
```


***

# Introduction

The `rctbayespower` package provides tools for conducting Bayesian power analysis for randomized controlled trials (RCTs) using the `brms` package and Stan.



# Basic Power Analysis Using ANCOVA Design



## Model

Show predefined models available in the package:
```{r}
list_predefined_models()
```


Get the predefined ANCOVA model for continuous outcomes with two arms:
```{r build_model_ancova}
model_ancova <- build_model(predefined_model = "ancova_cont_2arms")
model_ancova@parameter_names_brms
```

## Design

Find possible target parameters in the model.
```{r}
model_ancova@parameter_names_brms
```

Specify the study design with target parameter, thresholds for success and futility, and significance levels for frequentist-like power.
```{r build_design}
design <- build_design(
  model = model_ancova,
  target_params = "b_arm2",
  thresholds_success = 0.1,
  thresholds_futility = 0,
  p_sig_success = 0.9,
  p_sig_futility = 0.5
)
print(design)
```


### Conditions

Find parameters that need user specification for the design.
```{r}
required_fn_args(design)
```

Specify conditions.
```{r build_conditions}
conditions <- build_conditions(
  design = design,
  condition_values = list(
    # two sample sizes
    n_total = c(80, 160),
    # two effect sizes
    b_arm_treat = c(0, 0.3)
  ),
  static_values = list(
    # baseline effect
    b_covariate = 0
  )
)
print(conditions)
```


## Run Power Analysis

Run the analysis using the `power_analysis` function. This will run the model for each condition and return the results.
```{r run_sim}
power <- power_analysis(
  run = T,
  conditions = conditions,
  n_cores = n_cores,
  n_sims = n_sims
)

```


## Power for Effect of 0.3
```{r power_success}
power@summarized_results |>
  dplyr::filter(b_arm_treat != 0) |>
  dplyr::select(
    n_total,
    b_arm_treat,
    prob_success,
    prob_success_se,
    power_success,
    power_success_se,
    prob_futility,
    prob_futility_se,
    power_futility,
    power_futility_se
  ) |>
  dplyr::arrange(desc(b_arm_treat)) |>
  kableExtra::kable(digits = 3, format = "html")
```


## Alpha Error Rate for Null Effect

The power for success indicates the alpha error rate for the null effect (b_arm_treat = 0). This is the probability of rejecting the null hypothesis when it is true, which should be close to the significance level (0.05) if the design is well specified.

```{r power_null}
power@summarized_results |>
  dplyr::filter(b_arm_treat == 0) |>
  dplyr::select(
    n_total,
    b_arm_treat,
    prob_success,
    prob_success_se,
    power_success,
    power_success_se,
    power_futility,
    power_futility_se,
    prob_futility,
    prob_futility_se
  ) |>
  dplyr::arrange(desc(b_arm_treat)) |>
  kableExtra::kable(digits = 3,
                    format = "html")
```

## Run Time

```{r, code_fold=TRUE}
n_runs <- nrow(power@conditions@conditions_grid) * power@n_sims
cat("Total run time:", round(power@elapsed_time,1), "minutes for", n_runs, "total simulation repetitions using", power@n_cores, "cores.\n")
```

***


# Session Information

```{r session_info}
sessionInfo()
```
